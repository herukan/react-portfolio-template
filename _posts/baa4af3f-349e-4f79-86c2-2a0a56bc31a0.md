---
date: '2020-06-17T15:38:51.000Z'
title: Capstone Machine Learning - Airlines13
tagline: Capstone Machine Learning
preview: >-
  Case Airline13 dataset provides you with airline on-time data for all flights
  departed from Newark Liberty International Airport to Charlotte Douglas
  International Airport in 2013. The dataset includes records of flight
  departures and weather condition recorded per hour. Through this dataset, data
  scientists were challenged to solve one of the most frequent problems in
  airline industry– arrival delay status of a flight. Let’s put our data
  scientist knowledge into action and solve this problem using classification
  algorithms.
image: 'https://i.ibb.co.com/YcDXmyg/fgfgfggf.png'
---
# Case Airline13 dataset provides you with airline on-time data for
all flights departed from Newark Liberty International Airport to
Charlotte Douglas International Airport in 2013. The dataset includes
records of flight departures and weather condition recorded per hour.
Through this dataset, data scientists were challenged to solve one of
the most frequent problems in airline industry-- arrival delay status of
a flight. Let's put our data scientist knowledge into action and solve
this problem using classification algorithms.

# II. Dataset Metadata The train dataset contains detailed flight records
and weather condition recorded per hour from January 1st 2013 to
November 31th 2013. The data set can be joined by their recorded time.

The flight data consists of the following variables:

year,month,day: Date of departure. dep_time: Actual departure times
(format HHMM or HMM), local tz. sched_dep_time,sched_arr_time: Scheduled
departure and arrival times (format HHMM or HMM), local tz. dep_delay:
Departure delays, in minutes. Negative times represent early departures.
arr_delay: Flight arrival status; Delay or Not Delay. carrier: Two
letter carrier (airlines) abbreviation. flight: Flight number. tailnum:
Plane tail number. origin,dest: Airports of origin and destination.
hour,minute: Time of scheduled departure broken into hour and minutes.
distance: Distance between airports, in miles time_hour: Scheduled date
and hour of the flight (YYYYMMDD HHMMSS). The weather data consists of
the following variables:

year,month,day,hour: Time of recording. temp: Temperature in Fahrenheit.
dewp: Dewpoint in Fahrenheit. humid: Relative humidity. wind_dir: Wind
direction (in degrees). wind_speed: Wind speed (in mph). wind_gust: Wind
gust speed (in mph). precip: Precipitation, in inches. pressure: Sea
level pressure in millibars. visib: Visibility in miles. time_hour: Date
and hour of the recording (YYYYMMDD HHMMSS).

#III. Data Wrangling

``` {r}
library(readr)
library(dplyr)
library(caret)
library(gtools)
library(gmodels)
library(e1071)
library(tidyverse)
library(ggplot2)
library(lime)
library(lubridate)
library(recipes)
library(aCRM)
library(caret)
library(rsample)
```

## Loading Dataset

``` {r}
flight_train <- read.csv("dataset/data-train-flight.csv")
weather_train <- read.csv("dataset/data-train-weather.csv")
flight_test <- read.csv("dataset/flight-data-test.csv")
```

Sneak peak of the FLight dataset:

``` {r}
glimpse(flight_train)
```

## Assert Data Uniqueness:

``` {r}
unique(flight_train$year)
unique(flight_train$month)
unique(flight_train$day)
```

This dataset only contain one year of cycle, thus, the "year" coloumn
will be dropped

Sneak peak of the Weather dataset:

``` {r}
glimpse(weather_train)
```

``` {r}
unique(weather_train$year)
unique(weather_train$month)
unique(weather_train$day)
```

The flight and weather dataset occured on same circumstances of year
2013, so the dataset is valid to be merge.

Each Dataset Length:

``` {r}
length(flight_train$time_hour)
length(weather_train$time_hour)
```

## Merging Flight and Weather dataset As both dataset share same date and
time on "time_hour" coloumn, will be use this coloum as refrence on
joining dataset, however flight data only provide 4614, while weather
data of 7989 thus, 3,375 have no valid refrence of time and date and
will be dropped.

``` {r}
data_train_merged <- flight_train %>% 
  left_join(weather_train, by = "time_hour")
```

``` {r}
glimpse(data_train_merged)
```

##Droping Unecessary coloumns

``` {r}
unique(data_train_merged$year.x)
unique(data_train_merged$origin)
unique(data_train_merged$dest)
unique(data_train_merged$distance)
```

thats appear to be, the dataset only cover 1 origin and destination
place and range in the same year, thus, those particular coloumn will be
droped

``` {r}
data_train_merged <- data_train_merged %>% 
  select(-c(year.y, month.y, day.y, hour.y))
```

``` {r}
data_train_merged <- data_train_merged %>% 
  select(-c(year.x, origin, dest, tailnum, flight, sched_dep_time))
```

``` {r}
data_train_merged <- data_train_merged %>% 
  select(-c(distance))
```

``` {r}
glimpse(data_train_merged)
```

##Handling Missing Value

``` {r}
colSums(is.na(data_train_merged))
```

``` {r}
glimpse(flight_test)
```

``` {r}
glimpse(data_train_merged)
```

Adjusting merged dataset dtype and name matching them to test dataset
and extract "sched_arr_time" into hour and minute:

``` {r}
library(lubridate)
data_train_merged <- data_train_merged %>% 
  mutate(arr_delay = as.factor(arr_delay),
         time_hour = ymd_hms(time_hour), 
         day.x = as.character(wday(time_hour, label = T)),
         month.x = as.integer(lubridate::month(time_hour, label = F))) %>% 
  separate(sched_arr_time, into = c("sched_arr_hour", "sched_arr_minute"), sep = -2) %>% 
  mutate(sched_arr_hour = as.integer(sched_arr_hour),
         sched_arr_minute = as.integer(sched_arr_minute)) %>% 
  rename(month = month.x,
         day = day.x,
         arr_status = arr_delay,
         sched_dep_hour = hour.x,
         sched_dep_minute = minute) %>% 
  select(-c(dep_time, time_hour, carrier))
```

``` {r}
glimpse(data_train_merged)
```

# IV. Explanatory Data Analysis

### Flight Delay each airlines

``` {r}
ggplot(data = flight_train, aes(x=arr_delay, fill = arr_delay)) +
  geom_bar()+
  facet_wrap(~carrier)
```
![a](https://i.ibb.co.com/kcQR59k/sddfd.png)

According to the graph, delayed data only present in EV and US airlines

### Label Proportion

``` {r}
unique(flight_train$arr_delay)
table(flight_train$arr_delay)
prop.table(table(flight_train$arr_delay))
```

According to the table the delayed label have 66% Not delayed and 33%
Delayed data ratio which mean the dataset classess are quite balanced

Feature selection based on Testing Data:

``` {r}
features_name <- colnames(flight_test %>% select(-c("id")))
data_train <- data_train_merged[,colnames(data_train_merged) %in% features_name]
head(data_train)
```

Deleting Row with missing label:

``` {r}
data_trainku <- data_train[!(is.na(data_train$arr_status)),]
```

### Normality Test

Using Shapiro-Wilk Test Methode to assure the distribution of dataset
with specific coloumn "wind_dir"

``` {r}
shapiro.test(data_trainku$wind_dir)
```

p-value of the test result showing 2.2e-16 which below the default
threshold (0.05) which mean the dataset not normally distrubuted, so the
data imputation is needed

``` {r}
data_train_imputation <- imputeMissings(data_trainku)
```

### Oversampling minority class

Upsampling smaller class (delayed) using UpSample Function

``` {r}
train_up<- upSample(x = data_train_imputation,y = data_train_imputation$arr_status)
train_up <- train_up %>% mutate(arr_status = as.factor(arr_status)) %>% select(-c(Class))
```

### Dataset Distribution

Dataset will be distributed into Training and Validation set with 70:30
ratio

``` {r}
set.seed(46)
splitted <- initial_split(data = train_up, prop = 0.7, strata = "arr_status")
train_set <- training(splitted)
val_set <- testing(splitted)
```

# V. Classification

## Logistic Regression Model

``` {r}
model_log <- glm(formula = arr_status~., data = train_set, family = "binomial")
summary(model_log)
```

``` {r}
pred_prob <- predict(object = model_log, newdata = val_set, type = "response")
pred_label <- ifelse(pred_prob >= 0.5, "Delay", "Not Delay")
confusionMatrix(as.factor(pred_label), val_set$arr_status)
```

Logistic Regression Interprated the best independent variable such as
"month" and "wind_dir", however Logistic regression fail to convergent
showing less than 20% of accuracy

## Random Forest Model

setting up random forrest parameter grid search:

``` {r}
set.seed(46)
ctrl <- trainControl(method="repeatedcv", number = 5, repeats = 6, search = "grid")
```

``` {r}
#model_forest <- train(arr_status ~ ., data = train_set, method = "rf", trControl = ctrl)
#saveRDS(model_forest, "model_random_forest.RDS") # saving model
#model_forest
```

The Model training produce best accuracy of 88% with "mtry" parameter
value = 10

``` {r}
#loading model so we dont have to re train the model
model_rf <- readRDS("model_random_forest.RDS")
model_rf
```

##Interprating Feature Importance

``` {r}
varImp(model_rf, scale = FALSE)
```

In Random Forest Model the most representative feature is "dep_delay",
"humid" and "dewp"

### Validation test Prediction

``` {r}
model_rd_valid <- predict(object = model_rf,
        newdata  = val_set, 
        type = "raw")

confusionMatrix(data = model_rd_valid,
                reference = as.factor(val_set$arr_status))
```

On the validation set, random forest model produce 91% of accuracy, 89%
of Sensitivity and 92% of Specificity

#Model Evaluation According to the Model Evalutation, Random Forest
Model has the best performance, Hence, random forest model will be used
to evaluating testing set.

### Predict Testing set

``` {r}
#removing id coloumn
test_set <- flight_test %>% select(-c("id"))
test_set <- test_set %>% mutate(arr_status = as.factor(arr_status))
```

``` {r}
# Predict on the data test
pred_rf <- predict(object = model_rf,
        newdata  = test_set, 
        type = "raw")
```

``` {r}
# Create submission data
submission <- flight_test %>% 
  mutate(arr_status = pred_rf) %>% 
  select(id, arr_status)
```

``` {r}
# save data
write.csv(submission, "submission-rf11.csv", row.names = F)
```

``` {r}
# check first 10 data
head(submission, 10)
```

# VI. Interprating Random Forest Model with LIME Library

``` {r}
set.seed(46)
exp <- lime(x = train_set %>% select(-arr_status), model = model_rf)
exp_1 <- explain(x = test_set %>% select(-arr_status)%>% slice(1:4),
                       labels = "Delay",
                       explainer = exp,
                       n_features = 10)
plot_features(exp_1)
```

![a](https://i.ibb.co.com/PYrw758/fgfgg.png)

LIME with "n_permutations" parameter

``` {r}
explanation_02 <- explain(test_set %>% select(-arr_status) %>% slice(1:4), 
                       labels = "Delay",
                       n_permutations = 500,
                       dist_fun = "manhattan",
                       explainer = exp, 
                       kernel_width = 3,
                       n_features = 10)

plot_features(explanation_02)
```
![a](https://i.ibb.co.com/YcDXmyg/fgfgfggf.png)

According to LIME analysis the most representatif and usefull feature to
predicting delayed flight mostly consist of weather factor like "dewp",
"temp", and "humid"

# VII. Conclusion

According to analysis report, we can conclude that:

a.  There are two model created to predict delayed flight, Random
    Forrest with 91% of accuracy and Logistic Regression with lower than
    20% of accuracy.

b.  According to LIME analysis the most representatif and usefull
    feature to predicting delayed flight mostly consist of weather
    factor like "dewp", "temp", and "humid", predictor to those factor
    can be used to be top priority factor by aviation to improve their
    operation.

c.  The dataset is quite imbalance so upSampling method need to be
    implemented.

d.  p-value of the test result showing 2.2e-16 which below the default
    threshold (0.05) which mean the dataset not normally distrubuted, so
    the data imputation is needed
